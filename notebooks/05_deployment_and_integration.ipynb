{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-End Deployment & Integration for Real-Time Transaction Success Prediction\n",
    "\n",
    "This Jupyter Notebook provides a comprehensive implementation for deploying and integrating the best-performing transaction success prediction model from Phase 4 of our Transaction Success Rate Optimization Project.\n",
    "\n",
    "## Table of Contents \n",
    "1. [Load Best Model & Preprocess Data](#1-load-best-model--preprocess-data)\n",
    "2. [Build API with FastAPI](#2-build-api-with-fastapi)\n",
    "3. [Deploy Model as a Microservice](#3-deploy-model-as-a-microservice)\n",
    "4. [Implement CI/CD Pipeline](#4-implement-cicd-pipeline)\n",
    "5. [Conduct A/B Testing for Business Impact](#5-conduct-ab-testing-for-business-impact)\n",
    "6. [Monitor & Improve the Deployment](#6-monitor--improve-the-deployment)\n",
    "\n",
    "\n",
    "<a id=\"home\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1-load-best-model--preprocess-data\"></a>\n",
    "\n",
    "## 1. Load Best Model & Preprocess Data\n",
    "\n",
    "First, let's import necessary libraries and load our best-performing model.\n",
    "\n",
    "[Back to Top](#home)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\Documents\\Documents\\Personal Development\\Portfolio Projects\\transaction_success_optimization\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the absolute path of the parent directory\n",
    "sys.path.insert(0, os.path.abspath('../'))\n",
    "\n",
    "# import the necessary packages\n",
    "from src.dependencies import *\n",
    "from src.utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Define paths\n",
    "MODEL_PATH = \"../models/Optimized XGBoost.pkl\"\n",
    "PIPELINE_PATH = \"../models/feature_engineering_pipeline.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_and_pipeline():\n",
    "    \"\"\"\n",
    "    Load the trained model and preprocessing pipeline\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logger.info(f\"Loading model from {MODEL_PATH}\")\n",
    "        model = joblib.load(MODEL_PATH)\n",
    "        \n",
    "        logger.info(f\"Loading preprocessing pipeline from {PIPELINE_PATH}\")\n",
    "        preprocessing_pipeline = joblib.load(PIPELINE_PATH)\n",
    "        \n",
    "        return model, preprocessing_pipeline\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading model or pipeline: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 19:42:04,779 - __main__ - INFO - Loading model from ../models/Optimized XGBoost.pkl\n",
      "2025-03-22 19:42:04,972 - __main__ - INFO - Loading preprocessing pipeline from ../models/feature_engineering_pipeline.pkl\n",
      "2025-03-22 19:42:04,972 - __main__ - INFO - Model type: Pipeline\n",
      "2025-03-22 19:42:04,972 - __main__ - INFO - Pipeline type: Pipeline\n"
     ]
    }
   ],
   "source": [
    "# Load model and preprocessing pipeline\n",
    "model, preprocessing_pipeline = load_model_and_pipeline()\n",
    "\n",
    "logger.info(f\"Model type: {type(model).__name__}\")\n",
    "logger.info(f\"Pipeline type: {type(preprocessing_pipeline).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_transaction_data(transaction_data):\n",
    "    \"\"\"\n",
    "    Preprocess incoming transaction data using the feature engineering pipeline\n",
    "    \n",
    "    Args:\n",
    "        transaction_data (dict or pd.DataFrame): Raw transaction data\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Preprocessed transaction features ready for prediction\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert dict to DataFrame if necessary\n",
    "        if isinstance(transaction_data, dict):\n",
    "            transaction_df = pd.DataFrame([transaction_data])\n",
    "        else:\n",
    "            transaction_df = transaction_data.copy()\n",
    "            \n",
    "        # Apply the preprocessing pipeline\n",
    "        preprocessed_data = preprocessing_pipeline.fit_transform(transaction_df)\n",
    "        \n",
    "        return preprocessed_data\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error preprocessing transaction data: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def make_prediction(transaction_data):\n",
    "    \"\"\"\n",
    "    Make prediction on transaction success probability\n",
    "    \n",
    "    Args:\n",
    "        transaction_data (dict or pd.DataFrame): Raw transaction data\n",
    "        \n",
    "    Returns:\n",
    "        dict: Prediction results with success probability\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Preprocess the data\n",
    "        preprocessed_data = preprocess_transaction_data(transaction_data)\n",
    "        \n",
    "        # Make prediction\n",
    "        success_probability = model.predict_proba(preprocessed_data)[:, 1]\n",
    "        \n",
    "        # Prepare results\n",
    "        results = {\n",
    "            \"transaction_id\": transaction_data.get(\"transaction_id\", \"unknown\"),\n",
    "            \"success_probability\": float(success_probability[0]),\n",
    "            \"recommended_action\": \"route\" if success_probability[0] > 0.5 else \"review\"\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error making prediction: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction result: {'transaction_id': 'test-456', 'success_probability': 0.9820582270622253, 'recommended_action': 'route'}\n"
     ]
    }
   ],
   "source": [
    "# Test with a sample transaction\n",
    "sample_transaction = {\n",
    "    \"transaction_id\": \"test-456\",\n",
    "    \"timestamp\": \"2025-03-21 14:30:45\",\n",
    "    \"merchant_id\": \"MERCH00123\",\n",
    "    \"customer_id\": \"CUST002345\",\n",
    "    \"customer_location\": \"suburban\",\n",
    "    \"payment_amount\": 75.50,\n",
    "    \"payment_method\": \"credit_card\",\n",
    "    \"device_type\": \"mobile\",\n",
    "    \"network_latency\": 98.45,\n",
    "    \"result\": \"pending\",\n",
    "    \"latency_bin_encoded\": 2,\n",
    "    \"network_latency_scaled\": 0.142367,\n",
    "    \"merchant_rolling_avg_amount_scaled\": 0.05672,\n",
    "    \"merchant_success_rate_scaled\": 0.912345,\n",
    "    \"device_success_rate_scaled\": 0.974562,\n",
    "    \"payment_method_rolling_success_scaled\": 0.899874,\n",
    "    \"location_success_rate_scaled\": 0.765432,\n",
    "    \"payment_location_success_rate_scaled\": 0.832145,\n",
    "    \"merchant_transaction_count_log\": 4.56789,\n",
    "    \"hourly_transaction_volume_log\": 6.12345,\n",
    "    'amount_log': 4.321,\n",
    "    'merchant_rolling_avg_amount': 100.0,\n",
    "    'hourly_transaction_volume': 1000,\n",
    "    'merchant_success_rate': 0.95,\n",
    "    'time_of_day': 'afternoon',\n",
    "    'latency_bin': 'medium',\n",
    "    'day_name': 'Monday',\n",
    "    'amount_bin': 'low',\n",
    "}\n",
    "\n",
    "\n",
    "prediction_result = make_prediction(sample_transaction)\n",
    "print(f\"Prediction result: {prediction_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2-build-api-with-fastapi\"></a>\n",
    "\n",
    "## 2. Build API with FastAPI\n",
    "\n",
    "Now, let's create a REST API using FastAPI to serve our model.\n",
    "\n",
    "\n",
    "[Back to Top](#home)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Will watch for changes in these directories: ['c:\\\\Users\\\\USER\\\\Documents\\\\Documents\\\\Personal Development\\\\Portfolio Projects\\\\transaction_success_optimization\\\\notebooks']\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n",
      "INFO:     Started reloader process [7508] using StatReload\n",
      "INFO:     Stopping reloader process [7508]\n"
     ]
    }
   ],
   "source": [
    "# app.py content\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Load model and pipeline\n",
    "MODEL_PATH = \"../models/Optimized XGBoost.pkl\"\n",
    "PIPELINE_PATH = \"../models/feature_engineering_pipeline.pkl\"\n",
    "\n",
    "model = joblib.load(MODEL_PATH)\n",
    "preprocessing_pipeline = joblib.load(PIPELINE_PATH)\n",
    "\n",
    "# Initialize FastAPI app\n",
    "app = FastAPI(\n",
    "    title=\"Transaction Success Predictor API\",\n",
    "    description=\"API for predicting transaction success probability\",\n",
    "    version=\"1.0.0\"\n",
    ")\n",
    "\n",
    "# Define data models\n",
    "class TransactionData(BaseModel):\n",
    "    transaction_id: str = Field(..., description=\"Unique transaction identifier\")\n",
    "    timestamp: str = Field(..., description=\"Timestamp of the transaction in YYYY-MM-DD HH:MM:SS format\")\n",
    "    merchant_id: str = Field(..., description=\"Unique identifier for the merchant\")\n",
    "    customer_id: str = Field(..., description=\"Unique identifier for the customer\")\n",
    "    customer_location: str = Field(..., description=\"Location type of the customer (urban, suburban, etc.)\")\n",
    "    payment_amount: float = Field(..., description=\"Transaction payment amount\")\n",
    "    payment_method: str = Field(..., description=\"Payment method used (credit_card, bank_transfer, etc.)\")\n",
    "    device_type: str = Field(..., description=\"Type of device used for transaction (mobile, web, etc.)\")\n",
    "    network_latency: float = Field(..., description=\"Latency in milliseconds for transaction processing\")\n",
    "    result: str = Field(..., description=\"Transaction result (success, pending, failed)\")\n",
    "    \n",
    "    latency_bin_encoded: int = Field(..., description=\"Encoded category of network latency\")\n",
    "    network_latency_scaled: float = Field(..., description=\"Scaled network latency value\")\n",
    "    merchant_rolling_avg_amount_scaled: float = Field(..., description=\"Scaled rolling average transaction amount for the merchant\")\n",
    "    merchant_success_rate_scaled: float = Field(..., description=\"Scaled success rate of the merchant\")\n",
    "    device_success_rate_scaled: float = Field(..., description=\"Scaled success rate of transactions per device\")\n",
    "    payment_method_rolling_success_scaled: float = Field(..., description=\"Scaled rolling success rate for the payment method\")\n",
    "    location_success_rate_scaled: float = Field(..., description=\"Scaled success rate of transactions per customer location\")\n",
    "    payment_location_success_rate_scaled: float = Field(..., description=\"Scaled success rate of transactions per payment location\")\n",
    "    \n",
    "    merchant_transaction_count_log: float = Field(..., description=\"Log-transformed count of transactions for the merchant\")\n",
    "    hourly_transaction_volume_log: float = Field(..., description=\"Log-transformed transaction volume per hour\")\n",
    "    amount_log: float = Field(..., description=\"Log-transformed transaction amount\")\n",
    "    merchant_rolling_avg_amount: float = Field(..., description=\"Rolling average transaction amount for the merchant\")\n",
    "    hourly_transaction_volume: int = Field(..., description=\"Total transaction volume per hour\")\n",
    "    merchant_success_rate: float = Field(..., description=\"Overall success rate of the merchant\")\n",
    "    \n",
    "    time_of_day: str = Field(..., description=\"Time of the day category (morning, afternoon, evening, etc.)\")\n",
    "    latency_bin: str = Field(..., description=\"Latency bin category (low, medium, high)\")\n",
    "    day_name: str = Field(..., description=\"Name of the day (Monday, Tuesday, etc.)\")\n",
    "    amount_bin: str = Field(..., description=\"Transaction amount category (low, medium, high)\")\n",
    "\n",
    "    class Config:\n",
    "        json_schema_extra = {\n",
    "            \"example\": {\n",
    "                \"transaction_id\": \"test-456\",\n",
    "                \"timestamp\": \"2025-03-21 14:30:45\",\n",
    "                \"merchant_id\": \"MERCH00123\",\n",
    "                \"customer_id\": \"CUST002345\",\n",
    "                \"customer_location\": \"suburban\",\n",
    "                \"payment_amount\": 75.50,\n",
    "                \"payment_method\": \"credit_card\",\n",
    "                \"device_type\": \"mobile\",\n",
    "                \"network_latency\": 98.45,\n",
    "                \"result\": \"pending\",\n",
    "                \"latency_bin_encoded\": 2,\n",
    "                \"network_latency_scaled\": 0.142367,\n",
    "                \"merchant_rolling_avg_amount_scaled\": 0.05672,\n",
    "                \"merchant_success_rate_scaled\": 0.912345,\n",
    "                \"device_success_rate_scaled\": 0.974562,\n",
    "                \"payment_method_rolling_success_scaled\": 0.899874,\n",
    "                \"location_success_rate_scaled\": 0.765432,\n",
    "                \"payment_location_success_rate_scaled\": 0.832145,\n",
    "                \"merchant_transaction_count_log\": 4.56789,\n",
    "                \"hourly_transaction_volume_log\": 6.12345,\n",
    "                \"amount_log\": 4.321,\n",
    "                \"merchant_rolling_avg_amount\": 100.0,\n",
    "                \"hourly_transaction_volume\": 1000,\n",
    "                \"merchant_success_rate\": 0.95,\n",
    "                \"time_of_day\": \"afternoon\",\n",
    "                \"latency_bin\": \"medium\",\n",
    "                \"day_name\": \"Monday\",\n",
    "                \"amount_bin\": \"low\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "class PredictionResponse(BaseModel):\n",
    "    transaction_id: str\n",
    "    success_probability: float\n",
    "    recommended_action: str\n",
    "    prediction_time: str\n",
    "    model_version: str\n",
    "\n",
    "class FeedbackData(BaseModel):\n",
    "    transaction_id: str\n",
    "    actual_success: bool\n",
    "    prediction_probability: float\n",
    "    \n",
    "    class Config:\n",
    "        json_schema_extra = {\n",
    "            \"example\": {\n",
    "                \"transaction_id\": \"tx-12345\",\n",
    "                \"actual_success\": True,\n",
    "                \"prediction_probability\": 0.87\n",
    "            }\n",
    "        }\n",
    "\n",
    "class HealthResponse(BaseModel):\n",
    "    status: str\n",
    "    timestamp: str\n",
    "    uptime: float\n",
    "    model_version: str\n",
    "\n",
    "# Track API start time\n",
    "start_time = time.time()\n",
    "feedback_data = []\n",
    "\n",
    "# Helper functions\n",
    "def preprocess_transaction_data(transaction_data):\n",
    "    \"\"\"Preprocess transaction data using the pipeline\"\"\"\n",
    "    if isinstance(transaction_data, dict):\n",
    "        transaction_df = pd.DataFrame([transaction_data])\n",
    "    else:\n",
    "        transaction_df = pd.DataFrame([transaction_data.dict()])\n",
    "    \n",
    "    # Convert to expected format\n",
    "    return preprocessing_pipeline.fit_transform(transaction_df)\n",
    "\n",
    "def log_feedback(feedback: FeedbackData):\n",
    "    \"\"\"Log feedback data for later model retraining\"\"\"\n",
    "    feedback_data.append(feedback.dict())\n",
    "    \n",
    "    # If we've collected enough feedback, save to disk\n",
    "    if len(feedback_data) >= 100:\n",
    "        df = pd.DataFrame(feedback_data)\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        df.to_csv(f\"./feedback/feedback_data_{timestamp}.csv\", index=False)\n",
    "        feedback_data.clear()\n",
    "    \n",
    "    logger.info(f\"Feedback logged for transaction {feedback.transaction_id}\")\n",
    "\n",
    "# API endpoints\n",
    "app = FastAPI()\n",
    "\n",
    "# Get absolute path\n",
    "static_dir = os.path.join(os.path.dirname('__file__'), \"static\")\n",
    "\n",
    "# Ensure directory exists\n",
    "if not os.path.exists(static_dir):\n",
    "    os.makedirs(static_dir)\n",
    "\n",
    "# Mount the \"static\" directory\n",
    "app.mount(\"/static\", StaticFiles(directory=static_dir), name=\"static\")\n",
    "\n",
    "@app.get(\"/\")\n",
    "def read_root():\n",
    "    return {\"message\": \"Welcome to the Transaction Success Predictor API\"}\n",
    "\n",
    "@app.get(\"/favicon.ico\", include_in_schema=False)\n",
    "async def favicon():\n",
    "    favicon_path = os.path.join(static_dir, \"favicon.ico\")\n",
    "    if os.path.exists(favicon_path):\n",
    "        return FileResponse(favicon_path)\n",
    "    return {\"error\": \"favicon.ico not found\"}\n",
    "\n",
    "@app.get(\"/\", response_model=dict)\n",
    "async def root():\n",
    "    return {\"message\": \"Welcome to the Transaction Success Predictor API\"}\n",
    "\n",
    "@app.post(\"/predict\", response_model=PredictionResponse)\n",
    "async def predict(transaction: TransactionData):\n",
    "    \"\"\"\n",
    "    Predict transaction success probability\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Preprocess data\n",
    "        preprocessed_data = preprocess_transaction_data(transaction)\n",
    "        \n",
    "        # Make prediction\n",
    "        success_probability = float(model.predict_proba(preprocessed_data)[:, 1][0])\n",
    "        \n",
    "        # Determine recommended action\n",
    "        recommended_action = \"route\" if success_probability > 0.5 else \"review\"\n",
    "        \n",
    "        # Prepare response\n",
    "        response = {\n",
    "            \"transaction_id\": transaction.transaction_id,\n",
    "            \"success_probability\": success_probability,\n",
    "            \"recommended_action\": recommended_action,\n",
    "            \"prediction_time\": datetime.now().isoformat(),\n",
    "            \"model_version\": \"1.0.0\"\n",
    "        }\n",
    "        \n",
    "        logger.info(f\"Prediction made for transaction {transaction.transaction_id}: {success_probability:.4f}\")\n",
    "        return response\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error making prediction: {str(e)}\")\n",
    "        raise HTTPException(status_code=500, detail=f\"Prediction error: {str(e)}\")\n",
    "\n",
    "@app.post(\"/feedback\")\n",
    "async def feedback(feedback_data: FeedbackData, background_tasks: BackgroundTasks):\n",
    "    \"\"\"\n",
    "    Log transaction outcome feedback for continuous learning\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Process feedback in the background to not block the API\n",
    "        background_tasks.add_task(log_feedback, feedback_data)\n",
    "        return {\"status\": \"success\", \"message\": \"Feedback received\"}\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing feedback: {str(e)}\")\n",
    "        raise HTTPException(status_code=500, detail=f\"Feedback processing error: {str(e)}\")\n",
    "\n",
    "@app.get(\"/health\", response_model=HealthResponse)\n",
    "async def health_check():\n",
    "    \"\"\"\n",
    "    Check if the API is running correctly\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"status\": \"healthy\",\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"uptime\": time.time() - start_time,\n",
    "        \"model_version\": \"1.0.0\"\n",
    "    }\n",
    "\n",
    "# Run the API with uvicorn\n",
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "    uvicorn.run(\"app:app\", host=\"0.0.0.0\", port=8000, reload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n",
      "Response: {\n",
      "  \"transaction_id\": \"test-789\",\n",
      "  \"success_probability\": 0.9820582270622253,\n",
      "  \"recommended_action\": \"route\",\n",
      "  \"prediction_time\": \"2025-03-22T19:46:42.752450\",\n",
      "  \"model_version\": \"1.0.0\"\n",
      "}\n",
      "Status Code: 200\n",
      "Response: {\n",
      "  \"status\": \"success\",\n",
      "  \"message\": \"Feedback received\"\n",
      "}\n",
      "Status Code: 200\n",
      "Response: {\n",
      "  \"status\": \"healthy\",\n",
      "  \"timestamp\": \"2025-03-22T19:46:46.830827\",\n",
      "  \"uptime\": 10969.854054927826,\n",
      "  \"model_version\": \"1.0.0\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Define the API endpoint URL (assuming it's running locally)\n",
    "API_URL = \"http://localhost:8000\"\n",
    "\n",
    "# Test the predict endpoint\n",
    "def test_predict_endpoint():\n",
    "    sample_transaction = {\n",
    "        \"transaction_id\": \"test-789\",\n",
    "        \"timestamp\": \"2025-03-22 09:15:30\",\n",
    "        \"merchant_id\": \"MERCH00987\",\n",
    "        \"customer_id\": \"CUST004567\",\n",
    "        \"customer_location\": \"urban\",\n",
    "        \"payment_amount\": 150.75,\n",
    "        \"payment_method\": \"debit_card\",\n",
    "        \"device_type\": \"web\",\n",
    "        \"network_latency\": 120.67,\n",
    "        \"result\": \"success\",\n",
    "        \"latency_bin_encoded\": 3,\n",
    "        \"network_latency_scaled\": 0.189654,\n",
    "        \"merchant_rolling_avg_amount_scaled\": 0.07895,\n",
    "        \"merchant_success_rate_scaled\": 0.945678,\n",
    "        \"device_success_rate_scaled\": 0.985432,\n",
    "        \"payment_method_rolling_success_scaled\": 0.923456,\n",
    "        \"location_success_rate_scaled\": 0.812345,\n",
    "        \"payment_location_success_rate_scaled\": 0.876543,\n",
    "        \"merchant_transaction_count_log\": 5.12345,\n",
    "        \"hourly_transaction_volume_log\": 6.78901,\n",
    "        'amount_log': 5.012,\n",
    "        'merchant_rolling_avg_amount': 200.0,\n",
    "        'hourly_transaction_volume': 1200,\n",
    "        'merchant_success_rate': 0.97,\n",
    "        'time_of_day': 'morning',\n",
    "        'latency_bin': 'high',\n",
    "        'day_name': 'Tuesday',\n",
    "        'amount_bin': 'medium',\n",
    "    }\n",
    "    \n",
    "    response = requests.post(\n",
    "        f\"{API_URL}/predict\",\n",
    "        json=sample_transaction\n",
    "    )\n",
    "    \n",
    "    print(f\"Status Code: {response.status_code}\")\n",
    "    print(f\"Response: {json.dumps(response.json(), indent=2)}\")\n",
    "    \n",
    "    return response.json()\n",
    "\n",
    "# Test the feedback endpoint\n",
    "def test_feedback_endpoint(transaction_id, actual_success, prediction_probability):\n",
    "    feedback_data = {\n",
    "        \"transaction_id\": transaction_id,\n",
    "        \"actual_success\": actual_success,\n",
    "        \"prediction_probability\": prediction_probability\n",
    "    }\n",
    "    \n",
    "    response = requests.post(\n",
    "        f\"{API_URL}/feedback\",\n",
    "        json=feedback_data\n",
    "    )\n",
    "    \n",
    "    print(f\"Status Code: {response.status_code}\")\n",
    "    print(f\"Response: {json.dumps(response.json(), indent=2)}\")\n",
    "\n",
    "# Test the health endpoint\n",
    "def test_health_endpoint():\n",
    "    response = requests.get(f\"{API_URL}/health\")\n",
    "    \n",
    "    print(f\"Status Code: {response.status_code}\")\n",
    "    print(f\"Response: {json.dumps(response.json(), indent=2)}\")\n",
    "\n",
    "# Run the tests\n",
    "prediction = test_predict_endpoint()\n",
    "test_feedback_endpoint(\n",
    "    prediction[\"transaction_id\"],\n",
    "    True,\n",
    "    prediction[\"success_probability\"]\n",
    ")\n",
    "test_health_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Deploy Model as a Microservice\n",
    "<a id=\"3-deploy-model-as-a-microservice\"></a>\n",
    "\n",
    "Let's create a Dockerfile to containerize our API.  \n",
    "\n",
    "[Back to Top](#home)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 🚀 Running FastAPI Application with Docker\n",
    "\n",
    "##### **1️⃣ Install Docker**\n",
    "Ensure Docker is installed on your system. If not, download and install it from:  \n",
    "🔗 [https://www.docker.com/get-started](https://www.docker.com/get-started)\n",
    "\n",
    "---\n",
    "\n",
    "##### **2️⃣ Prepare the Required Files**\n",
    "Ensure your project directory contains:\n",
    "- `Dockerfile` (already provided)\n",
    "- `requirements.txt` (containing dependencies)\n",
    "- `app.py` (your FastAPI application)\n",
    "- A `models/` directory (if required by your app)\n",
    "\n",
    "---\n",
    "\n",
    "##### **3️⃣ Create the Dockerfile**\n",
    "Create a `Dockerfile` with the following content:\n",
    "\n",
    "```dockerfile\n",
    "# Use a lightweight Python base image\n",
    "FROM python:3.9-slim\n",
    "\n",
    "# Set the working directory\n",
    "WORKDIR /app\n",
    "\n",
    "# Copy requirements first for better caching\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# Copy model files\n",
    "COPY ./models/ ./models/\n",
    "\n",
    "# Create directory for feedback data\n",
    "RUN mkdir -p ./feedback\n",
    "\n",
    "# Copy the FastAPI application\n",
    "COPY app.py .\n",
    "\n",
    "# Expose port 8000\n",
    "EXPOSE 8000\n",
    "\n",
    "# Start the application using Gunicorn + Uvicorn\n",
    "CMD [\"gunicorn\", \"app:app\", \"--workers\", \"4\", \"--worker-class\", \"uvicorn.workers.UvicornWorker\", \"--bind\", \"0.0.0.0:8000\"]\n",
    "```\n",
    "---\n",
    "\n",
    "##### 4️⃣ Create a Build & Run Script\n",
    "\n",
    "Create a new file named build_and_run.sh and add the following content:\n",
    "```\n",
    "#!/bin/bash\n",
    "\n",
    "# Build Docker image\n",
    "docker build -t transaction-success-predictor:latest .\n",
    "\n",
    "# Run the container\n",
    "docker run -d -p 8000:8000 --name transaction-predictor transaction-success-predictor:latest\n",
    "\n",
    "echo \"✅ API is running at http://localhost:8000\"\n",
    "echo \"📄 Documentation available at http://localhost:8000/docs\"\n",
    "```\n",
    "\n",
    "##### 5️⃣ Grant Execution Permission to the Script\n",
    "\n",
    "Run the following command in your terminal to make the script executable:\n",
    "```\n",
    "chmod +x build_and_run.sh\n",
    "```\n",
    "##### 6️⃣ Build and Run the Docker Container\n",
    "\n",
    "Execute the script to build the Docker image and start the container:\n",
    "```\n",
    "./build_and_run.sh\n",
    "```\n",
    "##### 7️⃣ Verify That the API is Running\n",
    "\n",
    "Once the container is running, visit:\n",
    "\n",
    "🔗 [Base URL: ]('http://localhost:8000')http://localhost:8000  \n",
    "🔗 [Swagger Docs: ]('http://localhost:8000/docs')http://localhost:8000/docs\n",
    "\n",
    "##### 8️⃣ Stopping and Removing the Container\n",
    "\n",
    "To stop the running container:\n",
    "```\n",
    "docker stop transaction-predictor\n",
    "```\n",
    "To remove the container:\n",
    "```\n",
    "docker rm transaction-predictor\n",
    "```\n",
    "To delete the built Docker image:\n",
    "```\n",
    "docker rmi transaction-success-predictor:latest\n",
    "```\n",
    "\n",
    "##### 9️⃣ Deploy to AWS\n",
    "\n",
    "To deploy the application to AWS, run the deploy_to_aws.py script inside the app folder:  \n",
    "\n",
    "```\n",
    "python app/deploy_to_aws.py\n",
    "\n",
    "```\n",
    "\n",
    "Ensure that:  \n",
    "\n",
    "1. You have AWS CLI configured with the necessary credentials.\n",
    "2. The script is set up to handle deployment correctly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Implement CI/CD Pipeline\n",
    "\n",
    "<a id=\"4-implement-cicd-pipeline\"></a>\n",
    "\n",
    "Let's create a GitHub Actions workflow to automate our CI/CD pipeline.    \n",
    "\n",
    "[Back to Top](#home)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A yml file has been created `.github/workflows/deploy.yml` for GitHub Actions workflow to automate our CI/CD pipeline.  \n",
    "##### We can also use the unit test file `tests/test_app.py` to ensure our API is working correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conduct A/B Testing for Business Impact\n",
    "\n",
    "<a id=\"5-conduct-ab-testing-for-business-impact\"></a>\n",
    "\n",
    "We will implement an A/B testing framework to compare the old routing strategy versus our new model-based routing strategy with `ab_testing.py` file.    \n",
    "\n",
    "[Back to Top](#home)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Monitor & Improve the Deployment\n",
    "\n",
    "<a id=\"6-monitor--improve-the-deployment\"></a>\n",
    "\n",
    "Monitoring and development improvement will be done with the files `app/monitoring.py` and `scr/model_retrainig.py`.    \n",
    "\n",
    "[Back to Top](#home)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
